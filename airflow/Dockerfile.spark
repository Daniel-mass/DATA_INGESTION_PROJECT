FROM bitnami/spark:3.3.0

USER root

# Install Python and packages
RUN apt-get update && \
    apt-get install -y python3 python3-pip wget && \
    pip3 install --upgrade pip && \
    pip3 install kafka-python pyspark==3.3.0

# Create JARs directory and download required Kafka connectors
RUN mkdir -p /opt/bitnami/spark/jars && \
    wget -O /opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.3.0.jar https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.3.0/spark-sql-kafka-0-10_2.12-3.3.0.jar && \
    wget -O /opt/bitnami/spark/jars/kafka-clients-3.2.0.jar https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.2.0/kafka-clients-3.2.0.jar && \
    wget -O /opt/bitnami/spark/jars/spark-token-provider-kafka-0-10_2.12-3.3.0.jar https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.3.0/spark-token-provider-kafka-0-10_2.12-3.3.0.jar

# Copy Spark script
COPY ./scripts/spark_stream_processor.py /opt/bitnami/spark/scripts/spark_stream_processor.py

WORKDIR /opt/bitnami/spark

# Keep container alive
CMD ["tail", "-f", "/dev/null"]
